{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression for Classification with California Housing Data**\n",
        "\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "Welcome back to our machine learning adventure! Today, we'll dive into logistic regression, a powerful technique for classification tasks.  We'll use the same California housing dataset, but this time our goal will be to predict whether a house is \"expensive\" or \"affordable\" based on its features.\n",
        "\n",
        "**1. Libraries and Data Preparation**"
      ],
      "metadata": {
        "id": "er2V0r_8oh7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "xv8NWmeqoh7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing dataset\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "df = housing.frame\n",
        "\n",
        "# Define the target variable: Is the house expensive? (above median value)\n",
        "median_house_value = df['MedHouseVal'].median()\n",
        "df['Expensive'] = df['MedHouseVal'] > median_house_value\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(['MedHouseVal', 'Expensive'], axis=1)\n",
        "y = df['Expensive']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "icb0oq-roh7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Introduction to Logistic Regression**\n",
        "\n",
        "* **Classification:** Logistic regression is used to predict a categorical outcome (a class label). In this case, our labels are \"Expensive\" or \"Affordable.\"\n",
        "* **Probability:**  Logistic regression models the probability of a data point belonging to a specific class.\n",
        "* **Sigmoid Function:** The core of logistic regression is the sigmoid function, which transforms any value into a probability between 0 and 1.\n",
        "\n",
        "**3. Building the Logistic Regression Model**"
      ],
      "metadata": {
        "id": "to_NjjEboh7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "N1lO-Vppoh7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We increase `max_iter` to ensure convergence if needed.\n",
        "\n",
        "**4. Making Predictions and Evaluating**"
      ],
      "metadata": {
        "id": "8SE62Puzoh7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Confusion Matrix:\\n', conf_matrix)\n",
        "print('Classification Report:\\n', report)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "4cPMQCntoh7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Accuracy:** The proportion of correctly predicted labels.\n",
        "* **Confusion Matrix:** A table summarizing correct and incorrect predictions.\n",
        "* **Classification Report:** Provides precision, recall, F1-score, and support for each class.\n",
        "\n",
        "**5. Examining Feature Importance**"
      ],
      "metadata": {
        "id": "kbtEaHOpoh7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the coefficients (log-odds)\n",
        "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_[0]})\n",
        "\n",
        "# Sort by absolute value for magnitude of impact\n",
        "coefficients = coefficients.reindex(coefficients['Coefficient'].abs().sort_values(ascending=False).index)\n",
        "\n",
        "# Display the coefficients\n",
        "print(\"Feature Importance (Log-Odds):\\n\", coefficients.to_markdown(index=False))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "86OeQuMVoh7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Interpretation:** Coefficients in logistic regression are log-odds. A positive coefficient indicates a feature increases the probability of being in the \"Expensive\" class, and vice versa.\n",
        "\n",
        "**Visualize Feature Importance:**\n",
        "(Similar code as in linear regression example)\n",
        "\n",
        "**Student Challenges and Notes:**\n",
        "\n",
        "* **Probability Threshold:** Discuss how changing the probability threshold for classifying as \"Expensive\" can affect precision and recall.\n",
        "* **Class Imbalance:** If the dataset is imbalanced (e.g., far more \"Affordable\" houses), explore techniques like oversampling or undersampling.\n",
        "* **Advanced Models:** Introduce students to other classification models like Support Vector Machines or Random Forests."
      ],
      "metadata": {
        "id": "lTdNvJUaoh7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=coefficients, x='Coefficient', y='Feature')\n",
        "plt.title('Feature Importance (Absolute Coefficients - Log-Odds)')\n",
        "plt.xlabel('Coefficient Value (Log-Odds)')\n",
        "plt.ylabel('Feature')\n",
        "plt.grid(axis='x', alpha=0.75)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "XzXy6z1Fojp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "* The code will create a bar chart that will help visualize feature weights in the Logistic regression model.\n",
        "* **Data:** We use the `coefficients` DataFrame we created earlier, which contains the features and their corresponding log-odds coefficients.\n",
        "* **Bar Plot:**  `sns.barplot` is used to create a horizontal bar chart.\n",
        "    * **x-axis:** Shows the coefficient values (log-odds).\n",
        "    * **y-axis:** Displays the feature names.\n",
        "* **Title and Labels:** We set informative titles and labels for clarity.\n",
        "* **Grid:**  Adds a grid to make it easier to read the values.\n",
        "* **Show:** The `plt.show()` function displays the plot.\n",
        "\n",
        "**Interpretation:**\n",
        "* The length of each bar represents the magnitude of the feature's impact on the probability of a house being classified as \"Expensive.\"\n",
        "* The direction of the bar (positive or negative) indicates the direction of the effect:\n",
        "    * Positive: Higher values of the feature increase the likelihood of \"Expensive.\"\n",
        "    * Negative: Higher values of the feature decrease the likelihood of \"Expensive.\"\n",
        "\n",
        "**Student Challenges and Notes:**\n",
        "* **Understanding Log-Odds:** Discuss the concept of log-odds and how it relates to probability. Students might need a refresher on interpreting coefficients in logistic regression.\n",
        "* **Comparing Features:** Encourage students to analyze the plot. Ask them: Which features are the most important predictors of whether a house is \"expensive\"?\n",
        "* **Limitations:** Explain that feature importance in logistic regression isn't as straightforward as in linear regression due to the non-linear nature of the model."
      ],
      "metadata": {
        "id": "p7_8m_toojp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://www.techladder.in/article/decision-tree-detailed-explanation\">https://www.techladder.in/article/decision-tree-detailed-explanation</a></li>\n",
        "  <li><a href=\"https://note.com/nymnkun/n/n4dd2b2e2e271?magazine_key=m533a95a20eec\">https://note.com/nymnkun/n/n4dd2b2e2e271?magazine_key=m533a95a20eec</a></li>\n",
        "  <li><a href=\"https://iq.opengenus.org/smote-for-imbalanced-dataset/\">https://iq.opengenus.org/smote-for-imbalanced-dataset/</a></li>\n",
        "  <li><a href=\"https://github.com/Abbey225/my_app\">https://github.com/Abbey225/my_app</a></li>\n",
        "  <li><a href=\"https://github.com/Gaurav0771/Ml-Tutorials\">https://github.com/Gaurav0771/Ml-Tutorials</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "Dpb7Ibhroh7I"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}